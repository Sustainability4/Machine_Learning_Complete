Dimensionality reduction is a very important technique that helps overcome the issues of dimensionality curse and handling larger data. Here are some links of blogs below that will really help understand Dimensionality Reduction in detail.

1. [11 Different Uses of Dimensionality Reduction](https://towardsdatascience.com/11-different-uses-of-dimensionality-reduction-4325d62b4fa6)
2. [Dimensionality Reduction for Data Visualisation](https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29)
3. [Factor Analysis on Women Track Record Data with R and Python](https://towardsdatascience.com/factor-analysis-on-women-track-records-data-with-r-and-python-6731a73cd2e0)
4. [Importance of Dimensionality Reduction](https://medium.com/analytics-vidhya/importance-of-dimensionality-reduction-d6a4c7289b92)


# Dimensionality Reduction Techniques 

1. [Feature Selection for Dimensionality Reduction: Filter Methods](https://medium.com/analytics-vidhya/feature-selection-for-dimensionality-reduction-filter-method-201cc9eaa3b5)
2. [Feature Selection for Dimensionality Reduction: Wrapper Methods](https://medium.com/analytics-vidhya/feature-selection-for-dimensionality-reduction-wrapper-method-9979fffd0166)
3. [Feature Selection for Dimensionality Reduction: Embedded Methods](https://medium.com/analytics-vidhya/feature-selection-for-dimensionality-reduction-embedded-method-e05c74014aa)

# Feature Selection Techniques 
Remove less significant features from data so that model is trained only on significant features. 

## Filter Method 
1. Correlation Method
2. Chi Square Test
3. Anova 
4. Variance Inflation Factor

Source : [Link](https://github.com/Sustainability4/EDA_Cleaning_Feature/blob/8ad344235ea851355841a0d8c02a5ad940396d1f/eda%20+%20stats.pdf)

## Wrapper Method 
Step Forward and Step Backward Methods. Step Forward methods involve adding feature one by one to see the model training and performance and accordingly determine the importance of features. Go through Above link 

## Embedded Methods 

1. Lasso, Ridge and Elastic Net : [link](https://github.com/Sustainability4/Machine-Learning/tree/main/Regression)
2. XG Boost, Decision Tree and Random Forest : [link](https://github.com/Sustainability4/Machine-Learning/tree/main/Ensemble%20Techniques)



# Feature Extraction Techniques 
It is a method by which initial set of raw data is reduced to more manageable groups for processing.

## PCA 
1. PCA Basics : [Link 1](https://www.youtube.com/watch?v=fkf4IBRSeEc), [Link 2](https://www.youtube.com/watch?v=FgakZw6K1QQ)
2. Eigen values and Eigen Vectors : [Link](https://www.youtube.com/watch?v=ZSGrJBS_qtc)

## ICA 

1. Blog TDS : [Link](https://towardsdatascience.com/independent-component-analysis-ica-a3eba0ccec35)
2. Udacity Youtube Videos : [Link 1](https://www.youtube.com/watch?v=2WY7wCghSVI&t=1s), [Link 2](youtube.com/watch?v=wIlrddNbXDo)

## t-SNE 
1. Video : [Link](https://www.youtube.com/watch?v=NEaUSP4YerM)
2. Visualisation : [Link](https://distill.pub/2016/misread-tsne/#perplexity=2&epsilon=8&demo=11&demoParams=50)
3. Github : [Link](https://github.com/deveshSingh06/t-SNE/blob/master/t-SNE%20Implementation.ipynb)

## UMAP 
1. Video : [Stat Quest](https://www.youtube.com/watch?v=eN0wFzBA4Sc)
2. Blog : [Link](https://towardsdatascience.com/umap-dimensionality-reduction-an-incredibly-robust-machine-learning-algorithm-b5acb01de568)

## LDA : Linear Discriminant Analysis 
1. Video : [Link](https://www.youtube.com/watch?v=azXCzI57Yfc)
2. Blog : [Link](https://towardsdatascience.com/linear-discriminant-analysis-in-python-76b8b17817c2)

## SVD 
1. Repository Link : [Link](https://github.com/Sustainability4/The_Imperfects/tree/main/SVD)
